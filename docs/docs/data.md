# Data Analysis

## Summary

This page describes how screening data was processed in this project.

## Aim

- Identify binding interactions between P450s and compounds from UV-Visible light absorbance profiles between 220 and 800 nm from plate assay.
- Compensate for compound light absorbance in the sensitive area (390-420 nm) using control plates.
- Output a table of enzymes, compounds, a qualifitative or quantitative measure of binding and an indication of data quality.

## Procedure

During each screening experiment, data collected were:

- Plate data, which was exported to `.csv` files on the platereader host machine.
- *Echo* logs and exception reports, also `.csv` files.
- UV-Visible spectrometer readings taken when thawing, diluting and dispensing the target protein, exported to `.csv`s.

The key tasks are:

1. Use *Echo* picklists and exception reports to map compounds and their volumes to plate wells.
2. Match traces in platereader files to compounds and volumes.
3. Process and normalize traces, subtract control traces to correct for compound absorbance.
4. Detect and filter anomalies.
5. Quantify P450 absorbance profile response to compound concentration.
6. Get binding metrics $K_d$ and $V_{max}$ for each compound-P450 pair.

### Configuration and Data Processing 

Each experiment had a directory that looked like this:

```
02.0/                    
├── config.yml           # maps experiment directory for analysis
├── echo                 
│   ├── echo_logs        # surveys, exception reports etc
│   └── picklist         # 
├── img                  # output specs of 
├── nb                   # jupyter notebooks used for lab notes
├── platereader          # raw platereader data
└── uv-vis               # raw UV-Visible light spectroscopy data
```


Configuration files `config.yml` were generated in directory partly using the script `screening-fist/sxfst/scripts/config.py`, partly with human intervention.
`config.yml` contains experimental metadata that can be used to map compounds and their end volume in each well.
`yml` format was chosen because it's human friendly data structure and is easily handled with the `python` `yaml` library.
Each file looked like this:

``` yaml

echo:
  picklist:
  - ../../lab/02.0/echo/picklist/01-picklist.csv
  protocol:
  - ../../lab/02.0/echo/2022-04-23-exp02.epr
  surveys:
  - ../../lab/02.0/echo/2022-04-22/E5XX-1564_Survey_Source[4](UnknownBarCode).csv
  - ../../lab/02.0/echo/2022-04-22/E5XX-1564_Survey_Source[3](UnknownBarCode).csv
  - ../../lab/02.0/echo/2022-04-22/E5XX-1564_Survey_Source[2](UnknownBarCode).csv
  transfers:
  - ../../lab/02.0/echo/2022-04-22/E5XX-1564_Transfer_1650618552_Exceptions.csv
  - ../../lab/02.0/echo/2022-04-22/E5XX-1564_Transfer_1650618552.csv
nb:
- ../../lab/02.0/nb/design-01.ipynb
- ../../lab/02.0/nb/lab.ipynb
platereader:
  plate_1:
    control:
      date: 23/04/2022
      id1: null
      id2: null
      machine: BMG CLARIOstar
      path: ../../lab/02.0/platereader/TRno2900.CSV
      test_run_no: '2900'
      time: '16:30:14'
      user: USER
    test:
      date: 24/04/2022
      id1: null
      id2: null
      machine: BMG CLARIOstar
      path: ../../lab/02.0/platereader/24042022,0719350719.CSV
      test_run_no: '2930'
      time: 07:19:35
      user: USER
```

A script - `screening-fist/sxfst/scripts/data_proc.py` uses `config.yml` to map compounds and their volumes to absorbance traces from the platereader data.
It outputs a large `csv` table for each experiment with the meatadata and contents of each well and its complete, untreated traces.
This allows easier lookup of data in downstream tasks.

An ideal storage solution would be a structured database like `spark` for this data, since large files are unwieldly and lookups can be slow, whilst a database would be fast and can be sharded over multiple computing nodes to increase fault tolerance.

For this work, a set of large `csv` files is ok.

### Signal Processing and Anomaly Detection 

#### Aim

- Use the `csv` files generated by `data_proc.py` as input to:
- Generate a report for each enzyme-compound pair - with plots and metrics and a chemical structure.
- Extract $K_d$ and $V_{max}$ - two enzyme-compound binding metrics derived using the Michaelis-Menten steady state kinetics model.
- Generate a quality score - to indicate the reliability of the output metrics $K_d$ and $V_{max}$.

#### Approach

`screening-fist/sxfst/scripts/data_analysis.py` uses the `csv` files generated by `data_proc.py` as input like this:

1. Parse and concatenate the `csv` files.
2. For each experiment: locate wells and the corresponding compound and it's actual concentration - accounting for exceptions generated by the *Echo* and the corresponding control wells, with the same concentration of compound but no enzyme.
3. Normalize the raw traces for this subset by:
	1. Subtracting the $A_{800}$ from each trace, so that at 800 nm each trace has an absorbance of 0. 
	   This accounts for some scattering in the wells that can increase trace absorbance.
	2. Smooth each trace using a Gaussian filter ($\sigma = 2$). 
	   At low protein concentrations, the signal-noise ratio can be high, but can be adjsuted for.
4. Quantify the enzyme response in relation to compound concentration. 
   Traditionally, this is done by sbtracting the absorbance trace of protein with no compound from the traces with compound, which eccentuates the response - $\Delta \abs{A_{390}} + \abs{A_{420}}$, though this is not strictly necessary.
   This approach was problematic for this dataset due to the scattering effect that was common across wells. 
   The scattering effect increases the overall absorbance of the trace, particularly at the short wavelengths.
   The scattering effect can be described with:

   $$ Scattering = ? $$

   Where ...

   Initially, attempts to fit the Rayleigh scattering equation to the traces in order to correct for the effect proved ineffective ...

   Instead, an approach that is not sensitive to scattering was implemented instead.
   The new approach involves approximating the gradient of the traces at each point using a convolution of the matrix
   $[-1, 0, 1]$ across the trace.
   The gradient of each trace is invariant to absolute absorbance whilst showing changes in absorbance in the region of interest.
   The trace gradients can be used to quantitatify the P450 response using the $\Delta \frac{\delta y}{\delta x}$ at 405 nm, between the two peaks of interest.
5. The compound-enzyme concentration-response data can be quantified by fitting a Michaelis-Menten steady-state kinetics curve to the data points, which yields the binding metrics $K_d$ which indicates the strength of the protein-compound interaction, and $V_{max}$ which indicates the response magnitude of the enzyme to the compound. 
For each experiment, curves were fit using `scipy.optimize.curve_fit`, which itself uses `trf?`.
For each curve fit, $R^2$ served as a fit quality metric.

These steps were applied to each experiment, yeilding a little over 4000 data points.

That's tight


### Response Qualification and Quantification 
