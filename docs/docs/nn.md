# Model

## Summary

$$
P_{binding} = fn(sequence, smiles)
$$

This page describes the deep learning model constructed for this project.
The model is designed to estimate the likelihood of a binding interaction between a given Cytochrome P450 sequence and a ligand SMILES code.
The intended end uses of the model are:

1. Virtually screening sequences for potential activity with a given compound.
2. Optimally design an enzyme-ligand screening experiment.

## Aim

- [ ] Build and train a model that: 
	- [x] Takes input enzyme sequence and a compound SMILES and outputs an estimate of binding likelihood interaction between the two.
- [ ] Pre-train prototype on large sequence-smiles dataset and save weights.
	- [x] Set up GPU machine
	- [ ] Run for $n$ iterations, save weights
	- [ ] Run again with validation
	- [ ] Outputs uncertainty

## Approach

Abstractly, the problem of predicting the binding likelihood between a one of $m$ protein and one of $n$ small molecules can be represented an $n \times m$ matrix, where rows and columns refer to proteins and small molecules and values are the probability of a binding interaction between the two:


\begin{matrix} 
 & compound_i & compound_{i+1} & ... & compound_{i+n} \\
sequence_i  & P_{binding_{i,j}} & ... & ... & ...\\  
sequence_{i+1} & ... & ... & ... & ... \\
... & ... & ... & ... & ... \\
sequence_{i+m} & ... & ... & ... & ... \\
\end{matrix}

Some $P_{binding}$ values are known, which in the perspective of $n \times m$ possible values where $n$ and $m$ approach infinity, coverage is sparse.

This type of problem has been addressed in recommender systems, which in the context of streaming services translates to a matrix of $n$ users and $m$ peices of content.
Known values are likes and engagement metrics and are similarly sparse, and blanks can be filled with the probability of a successful recommendation.

Machine learning models can be trained to predict the unknown values based on a numerical representation of the user and content.
The prediction can be cast as a classification problem.
To overcome the lack of negative data points, presumed negative data can be generated by sampling a random user: content pair, which should be treated with caution.

In this work, a machine learning model classifies pairs of protein sequence and small molecules as binding or not.
Negative samples are generated by randomly sampling a sequence and small molecule, which given the vastness of sequence and chemical space may be resonable in a large number of cases.
Nonetheless, this assumption is treated with caution.

Small molecules are represented as SMILES codes in the dataset, which are parsed using `rdkit` and then into 2048 bit fingerprint vectors using the `RdkitFingerprint`

## Data

It was important to improve the sample efficiency of the model as far as possible, given the cost of lab data acquisition.
This was done by:

1. Application of a pre-trained model
2. Further pre-training the model on task-specific data

### Pre-Training Data

### Training Data

## Model 

The model aims to predict:
$$
P_{binding} = fn(sequence, smiles)
$$
Where $fn$ is a model that takes an input of a protein $sequence$ and a prospective ligands' SMILES code - $smiles$ and outputs $P_{binding}$ - an estimate of the probability that the given $sequence$ and $smiles$ bind to one another.

Given their prior success in chemical and protein sequence learning, a neural network model was chosen to build  $fn$.
The network can be split into three parts:


- **Sequence Embedding:** For a given protein $sequence$, output a tensor encoding a neural embedding $z_{sequence}$.
- **Chemical Embedding:** For a given chemical $smiles$ encoding, outputs an embedding $z_{smiles}$.
- **Prediction Head:** For the embeddings $z_{smiles}$ and $z_{sequence}$, output a prediction $P_{binding}$.

### Sequence Embedding
### Chemical Embedding
### Prediction Head

## Training

## Active Learning
